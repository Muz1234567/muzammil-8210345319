{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94e48c81",
   "metadata": {},
   "source": [
    "# Queno1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9696c463",
   "metadata": {},
   "source": [
    "# R squared In Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee05eb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#R squared is a statistical measure in regression model that determines the proportion of variance in dependent variable\n",
    "#that can be explained by independent variable also r squared shows how well thedata fit the regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bcbbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets suppose if an r squared of 50% reveals that 50% of the variability observed in the target variable is explained \n",
    "#by the regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafd6a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generally a higher r squared indicates more variability is explained by the model and low r squared is generally bad \n",
    "#sign for predictive models while in some case a good model show a small value r square. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a5f5dc",
   "metadata": {},
   "source": [
    "# R squared Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e590c052",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets create dataset of x and y variable where x is predictor andy isresponse variable.\n",
    "#x=3,5,6,7,9=30\n",
    "#y=22,24,26,21,27=120\n",
    "#Now calculate x**2,y**2 and xy\n",
    "#x**2=9,25,36,49,81=200\n",
    "#y**2=484,576,676,441,729=2906\n",
    "#xy=66,120,156,147,243=732\n",
    "#formulaefor rsquare=[n*total value of xy-(total value ofx)(total value of y)/(squarertn*total vaslue ofx**2-(total value \n",
    "#of x)**2*sqrtn*tital value of y**2-(total value of y)**2]**2\n",
    "#r squared=[5*732-3600/sqrt5*200-(30)**2*sqrt5*(2906)-(120)**2]**2\n",
    "#r square=[3660-3600/-452.78*-7901.98]**2\n",
    "#r square=[60/3577858.5]**2\n",
    "#r square=[0.000001676]**2\n",
    "#r square=0.000000000002804\n",
    "#hence 0.000000002802 % of the variation of variable y can be explained in variablex. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10499684",
   "metadata": {},
   "source": [
    "# Queno 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ac5523",
   "metadata": {},
   "source": [
    "# Adjusted R square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fcff2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjusted r square is a modified version of R squared that has been adjusted for number of predictors in model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65698ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It increases when new term improves the model more than would expected by chance and it decreases when predictor improves\n",
    "#the model by less than expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6159c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjusted R square is used to determine how reliable the corelation is and how much it is determined by the addition \n",
    "#of independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1e6db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjusted r square compensates for addition of variables andonly increases if new predictor enhance model and decrease\n",
    "#when predictor improves the model less than what predictedby chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8db9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rsquare is used to indicate how well a regression model predicts responses for new observations while adjusted r square\n",
    "#can provide an accurate model that fits current data whereas  r square determines how likely it is that this model\n",
    "#will be accurate for future data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a78233e",
   "metadata": {},
   "source": [
    "# Queno 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f982c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppose lets take three variable x1,x2,y1 and with this variables we can run two regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c781704",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regression 1 x2(input variable),y1(output variable) yields an r square of 0.9557 and an adjusted r square of 0.9493."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac43bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regression 2 x1(input variable),x2(input variable),y1(output variable) yield an r square of 0.9573 and an adjusted \n",
    "#r square of 0.9431."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8457c0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#So the adjusted r square in regression 1 is 0.9493 compared to regression 2 of 0.9431 therefore it shows that \n",
    "#input variable x1 is not helpful in explaining output variable y1 . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b21b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In such case the adjusted r square would point the model creator to using regression 1 rather than regression 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6f4b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this way adjusted r square works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035137c4",
   "metadata": {},
   "source": [
    "# Queno 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671074d5",
   "metadata": {},
   "source": [
    "# Root Mean Squared Error,Mean Absolute Error,Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aa4eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Root Mean Squared Error is the square root of Mean squared error and it measures the standard deviation of residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df89c42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Absolute Error represents average of absolute difference between the actual and predicted values in dataset and it \n",
    "#measures the average of residuals in dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee855b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean squared error represents the average of squared difference between original and predicted values in dataset and it\n",
    "#measures the variance of residuals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85309aa",
   "metadata": {},
   "source": [
    "# Calculation Of RMSE,MAE AND MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0803e309",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets take 4 variables as feature1,feature2,actual value and predicted value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53f89db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature1=2,3,4,5,6\n",
    "#feature2=3,4,5,6,7\n",
    "#actual value=4,5,6,7,8\n",
    "#predicted value=6,7,7,8,9\n",
    "#now we have to calculate residual error=(actual-predicted)\n",
    "#residual error=-2,-2,-1,-1,-1\n",
    "#now we can calculate MSE by taking average of squared residual errors\n",
    "#MSE=4+4+1+1+1=11/5=2.2\n",
    "#TO calcualte MAE we have to take average of residual errors sum\n",
    "#MAE=7/5=1.4\n",
    "#To calcualte RMSE we have to take squareroot of MSE\n",
    "#RMSE=sqrt2.2=1.48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080a95d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#So in this way we are able to calculate RMSE,MAE and MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124b9659",
   "metadata": {},
   "source": [
    "# Queno 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faada05b",
   "metadata": {},
   "source": [
    "# Advantages And Disadvantages Of RMSE,MSE And MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dea385",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSE is widely used loss function for regression problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8455904",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It can be useful in situation where goal is to minimize the overall error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd6f5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSE disadvantage is that it is sensitive to outliers and it can be difficult to interpret values since they are squared. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9868f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAE is less sensitive to outliers than MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35375b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAE does not take into account the direction of error and it can be difficult to interpret values since they are absolute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9360c762",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSE is the aggregated mean and subsequent squareroot of these errors which helps us understand model performance over the \n",
    "#whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd70870",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSE is highly sensitive to outliers in dataset and outliersn have to be removed for it to function properly and RMSE ALSO\n",
    "#also increases with an increase in the size of test sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15cef0e",
   "metadata": {},
   "source": [
    "# Queno 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275ed1c5",
   "metadata": {},
   "source": [
    "# Lasso regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426ff321",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LASSO stands for least absolute shrinkage and selection operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17ad7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It is also known as l1 regularization technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55e5f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso regularization adds penalty that is equal to absolute value of the magnitude of the coefficient which can result in\n",
    "#sparse models with few coefficients in which some coefficient might become zero andget eliminated from model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0e16bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Larger penalties result in coefficient values that are closer to zero while in ridge regularisation does not result in any\n",
    "#elimination of sparse models or coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d330c3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thus lasso regulsrisation is easier to interpret than ridge regularisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69293bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso can be used in multiple linear regression when we want sparse model as like when we have large set of variables \n",
    "#but only small number of them are truly important in this lass is used. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f223b062",
   "metadata": {},
   "source": [
    "# Queno 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07c53c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regularized linear model means a set of parameters that constrain,regularizes or shrinks the coefficient estimates \n",
    "#towards zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efaff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In other words this type of model discoursages learning more complex or flexible model which avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d700982",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For example lets consider one of regularization technique that is lasso regression which shrinks the coefficient of model\n",
    "#to zero,so it performs feature selection and eliminates irrelevant or redundant features from model which help in \n",
    "#reducing dimensionality and noise of data which prevent overfitting in model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672eed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this different types of regularization technique works in their way to prevent overfitting in linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2f5c98",
   "metadata": {},
   "source": [
    "# Queno 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4893e6",
   "metadata": {},
   "source": [
    "# Limitation of Regularised Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c0a703",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regularization leads to dimensionality reduction in dastaset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c09f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimensionality reduction means machine learning model is built using lower dimensional dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21182fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This generally leads to high bias error.This is the resason some time regularization technique is not suitable for \n",
    "#regression analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423cbc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thats why a perfect balance between bias variance tradeoff must be used before performing regularization technique in \n",
    "#linear models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0b602c",
   "metadata": {},
   "source": [
    "# Queno 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212c28af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A higher RMSE indicates that there is large deviation from residual while lower RMSE the better the model and its\n",
    "#prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcb848f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In MAE in model the lower MAE indicates superior model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652508dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#So model with MAE 8 could be better performer as compared to RMSE 10 as MAE is easy to calculate and all errors are \n",
    "#weighted on same scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823dcea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are some limitations of MAE metric that it does not differentiate between overestimation and underestimation,also\n",
    "#it cannot be  appropriate to use MAE when direction of errors is crucial in problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dde9b7",
   "metadata": {},
   "source": [
    "# Queno 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42134fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso regression is used for eliminating outomated variables or features used for selection of features in model while\n",
    "#Ridge regularisation tries to balance bias variance tradeoff by shrinking coefficients but does not select any feature \n",
    "#and keeps all thus it is used only for model shrinkage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08e6b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thus lasso regularisation is considered to be better than ridge as it only select some features and decreases the \n",
    "#coefficients of others to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315c3695",
   "metadata": {},
   "outputs": [],
   "source": [
    "#So we can say that model with lasso regularisation parameters 0.5 is considered best to use than ridge regularisation\n",
    "#parameters 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8eeb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso cannot be used in highly corelated feature dataset as it chooses only one feature or variable among highly\n",
    "#corelated feature groups of dataset so it can be used in small feature variable dataset not in large feature variable\n",
    "#dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c4ebe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
