{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0aa5921",
   "metadata": {},
   "source": [
    "# Queno 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da45e5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid search cv is a technique in machine learning to search through the best parameter values from given set of grid of \n",
    "#parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bee1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid search cv can also be used as library in python in which user needs to give different set of values for important\n",
    "#parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015d7cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gridsearchcv by cross validations will find out the best value for parameters mentioned in which predictions are made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888dedae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After that it gives the score after evaluating the data on best parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273a6e05",
   "metadata": {},
   "source": [
    "# Queno 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f07812",
   "metadata": {},
   "source": [
    "# Gridsearchcv vs Randomisedsearchcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccb22a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid search is a method for hyperparameter optimization that involves specifying a list of values for each hyperparameter\n",
    "#that we want to optimize while in randomisedsearchcv instead of specifying a list of values for each hyperparameter we\n",
    "#specify a distribution for each hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfc5431",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid search algorithm would then train a model using every combination of these values and evaluate the performance of\n",
    "#each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9efd491",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomised search algorithm sample values for each hyperparameter from its corresponding distribution and train a model\n",
    "#using sampled values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87b7d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimal values for hyperparameters are chosen based on performance of models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f8b2c8",
   "metadata": {},
   "source": [
    "# Queno 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f809c480",
   "metadata": {},
   "source": [
    "# Data Leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3526565",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data leakage is a condition in machine learning model when model is already aware of some part of test data after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b701290",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This can also lead to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b738069",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Due to this we got unrealistically high levels of performance of our model on the test set,because that model is being\n",
    "#run on data that it had already seen in some capacity in training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac0d252",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then model effectively memorizes thetraining dataset and is easily able to correctly output the labels or values for those\n",
    "#examples of test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b75e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#When such model is used on truly unseen data then the performance of that model will be lower than expected after \n",
    "#deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f385a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example; To properly evaluate particular machine learning model we split our available data into training and test subsets\n",
    "#which leads to some of information from test set is shared with train set which leads to data leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11968089",
   "metadata": {},
   "source": [
    "# Queno 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767fd6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are many techniques through which we can prevent data leakage among them is regularization which can prevent data\n",
    "#leakage by reducing models reliance on specific features or subsets of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5d3fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing steps should be based on training set not on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facbdecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data should be properly shuffled before applying cross validation to prevent leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff38b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#There should be no overlap between data in training,validation and test sets to prevent leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff742fc4",
   "metadata": {},
   "source": [
    "# Queno 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4346d9",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542281f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix summarizes the performance of machine learning model on a set of test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243523d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It displays the number of accurate and inaccurate instances based on models predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18e6443",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of instances produced by model on test data that is \n",
    "#1.True positives;It occurswhen model accurately predicts a positive data point.\n",
    "#2.True negatives;It occurs when model accurately predicts negative data point.\n",
    "#3.False positive;It occurs when model predict posditive data point incorrectly.\n",
    "#4.False negatives;It occurs when model mispredicts a negative data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a11d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix tells the performance of classification models when they make predictions on test data and tells how\n",
    "#good our classification model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067e0a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It tells the error made by classifier and also type of errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d2d5ba",
   "metadata": {},
   "source": [
    "# Queno 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a39c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision and recall are metrics used in confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d448374",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision is a metric that tells us about quality of positive predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae9fb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recall is a metric that tells us how well model identifies true positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0635e579",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision is calculated #true positives/All actual positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcd35fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recall is calculated using true positives/all actual positives=true positives/false negatives+true positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7194fee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A model with higher recall than precision makes more positive predictions which has higher false positives and low false \n",
    "#negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d6b35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A model with higher precisdion will have fewer false positive and more false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09b64a2",
   "metadata": {},
   "source": [
    "# Queno 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdb7d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are two types of error that type 1 error(false positive) and type 2 error(false negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f77607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Type 1 error occurs when model predicted positive result different from negative result which is real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7e61a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Type 2 error occurs when model predicted negative result different from positive resuilt which is real."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a32978",
   "metadata": {},
   "source": [
    "# Queno 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056ee10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Common metrics derived from confusion metrics are;Accuracy,Precision,Recall,F1score,Specificity etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7191e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy is used to measure the performance of model which isratio of total correct instances to total instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33005087",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy=True positive+true negative/true positive+true negative+false positive+false negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69657386",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision is defined as ratio of true positive predictions to total no of positive predictions made by model which measures\n",
    "#how accurate a models positive predictions are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffea0da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision=True positive/True positive+false positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7646c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recall is the ratio of no of truepositive instances to sum of true positive and false negative instances which measures\n",
    "#the effectiveness of classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9f8c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It is calculated as recall=Total positive/total positive+false negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6168fc",
   "metadata": {},
   "source": [
    "# Queno 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f8d39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relationship between model accuracy and its values in four ways are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5b1ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#True positive;It is the total counts having both predicted and actual values as positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca891835",
   "metadata": {},
   "outputs": [],
   "source": [
    "#True negative;It is the total counts having both predicted and actual values are negative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c6994e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#False positive;It is the total counts having prediction positive while actually it is negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fe686f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#False negative;It is the total counts having prediction negative while actually it is positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3d9bb0",
   "metadata": {},
   "source": [
    "# Queno 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc15aea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix evaluates the performance of the classification models at time of predictions on test data and tells\n",
    "#how good our classification model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cf9ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#With the help of confusion matrix we calculate different parameters such as accuracy,precision etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb9ba54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy is one of the important parametersto determine accuracy of classification model and it also defines how often\n",
    "#model predicts the correct output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567ddc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision defined as the number of correct outputs provided by model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45237d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recall is defined as out of total classes how much our model predicted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6f9fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
