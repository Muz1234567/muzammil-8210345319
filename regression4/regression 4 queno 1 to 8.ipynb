{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48a5971e",
   "metadata": {},
   "source": [
    "# Queno 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160959d1",
   "metadata": {},
   "source": [
    "# Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c24116",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso regression is a regularization technique used in model for shrinkage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1b169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In shrinkage where data values are shrunk towards central point as mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01288627",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This procedure encourages simple and sparse models with few parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764730ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This type of regression is well suited for models showing high levels of multicollinearity or when we want to automate\n",
    "#certain certain parts of model selection like variable selection or parameter elimination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90a6d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso regression assumes a relationship between the independent variables and the dependent variables y=beta[]+beta[]x[]\n",
    "#+beta2x2+...+beta[]x[]+e in this form\n",
    "#where y isdependent variable\n",
    "#beta[] are the coefficients to be estimated\n",
    "#x[] are independent features to be estimated and e representsa error term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4b0e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After that this regression introduces regularization based on absolute values of coefficients and the sum ofabsolute values\n",
    "#of coefficient is multiplied by tuning parameter lambda where it controls amount of regularization applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba3001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The choice of regularization parameter is important in LASSO regression where a larger lambda value increases amount \n",
    "#amount of regularization leading to more coefficients pushed towards zero and smaller lambda value reduces regularization\n",
    "#effect leading more variables to be non zero coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9afb241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso regression is different from other regression as it uses l1 regularization for model shrinkage also referred as\n",
    "#penalized regression method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a164ae18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This methods leads to sparse model where some coefficients become zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c406b0",
   "metadata": {},
   "source": [
    "# Queno 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5672824f",
   "metadata": {},
   "source": [
    "# Advantages of Lasso Regression in Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685a4e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso regression uses l1 regularization which leads to make coefficients of some features to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a642bd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This means that some features are effectively ignored in the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb414b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#So in this way it leads to sparse model and reduces the risk of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84a5519",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso works well with high dimensional data and is effective when dealing with datasets with many features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22632a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It identifies the most important features and makes model more interpretable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8ac45a",
   "metadata": {},
   "source": [
    "# Queno 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bed5d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso regression force coefficients towards zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931618ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This regression uses l1 regularization to make coefficients of some feature to zero which leads to reduce some features \n",
    "#in dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16608a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The smaller the coefficients the less important it is or less variance it explains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea045f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A zero coefficients suggest features exclusion from model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16a24d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#While a non zero coefficients suggest features importance in model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6d4953",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For example a feature coefficient 30 has more predictive power or importance than one with a value if 20 or 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c8ba81",
   "metadata": {},
   "source": [
    "# Queno 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790e00e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning parameter(lambda) also called penalty parameter controls the strength of penalty term in lasso regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea34d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It is basically the amount of shrinkage where data values are shrunk towards central point like mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b883d51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#When lambda=0 no parameters are eliminated and as lambda increases more and more feature coefficient are set to zero and \n",
    "#and this led to eliminate that feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a341c262",
   "metadata": {},
   "outputs": [],
   "source": [
    "#When lambda =infinity all coefficients are eliminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ae902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#When lambda increases bias increases and as lambda decreases variance increases.For example setting lamda to low value \n",
    "#results in more manageable model parameters and lower bias and higher variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7d2b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#So lasso regression introduces lasso regularization and with the help of tuning parameter (lambda) limits the size of \n",
    "#coefficients and can result in sparse models ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c46cbb6",
   "metadata": {},
   "source": [
    "# Queno 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac9b79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Yes lasso regularization can be used in non linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904c3611",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can impose a lasso penalty on nonlinear regression model and select the number of basis function effectively.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d60094",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can select tuning parameter in regularization method derived from bayesian method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a76b20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can also construct nonlinear regression model with gaussian basis function using lasso regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb82fae",
   "metadata": {},
   "source": [
    "# Queno 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99945e40",
   "metadata": {},
   "source": [
    "# Difference between Ridge Regression and Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07db672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rigde regression adds apenalty equal to square of magnitude of coefficients while lasso regression adds penalty equal\n",
    "#to absolute value of magnitude of coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff63363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge regression shrinks the coefficients towards zero to reduce model complexity and multicollinearity while lasso\n",
    "#regression shrink some coefficients towards zero for both variable reduction and model simplification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2748b5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All features are included in model in ridge regression but their impact is minimized while lasso regression perform feature\n",
    "#selection and can completely eliminate some features by setting their coefficients to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eb126c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge regression is suitable when there is multicollinearity and lasso regression is used to identify most important \n",
    "#features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbedd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge regression generally results to more complex model compared to lasso as irrelevant features are abundant in lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd73fd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge regression model is less interpretable due to presence of many features while lasso regression model is more \n",
    "#interpretable due to feature elimination focussing on important features only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f4d0e3",
   "metadata": {},
   "source": [
    "# Queno 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835b875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso regression is used for eliminating less significant features from model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234a3e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It adds lasso regularization and shrink coefficient towards zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83726e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#When tuning parameter lambda is sufficiently large some coefficients are driven to exactly zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6da287",
   "metadata": {},
   "outputs": [],
   "source": [
    "#So these zero coefficient feature variables are considered as less important and are effectively removed from model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eab5387",
   "metadata": {},
   "source": [
    "# Queno 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c5ba38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can choose different sequence of tuning parameters andwith these can create different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14113c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After that we can select that model the one that best fits our requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2418a1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#When tuning parameter =0 then no parameters are eliminated,when it increases more and more feature coefficients are \n",
    "#set to zero and eliminated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806e6112",
   "metadata": {},
   "outputs": [],
   "source": [
    "#So by using this method we can create different models with different tuning parameters and select the best one that needs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43548f21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf8d766",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
