{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd419711",
   "metadata": {},
   "source": [
    "# Queno1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf4cd7f",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d119ad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge regression is a statistical regularization technique and it also corrects for overfitting on training data in machine\n",
    "#learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cab267",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It is also known as l2 regularization and it reduce errors caused by overfitting on training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821dce52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It is also used for specifically for correcting multicollinearity in regression analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850bf80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#When the issue of multicolinearity occurs least squaresare unbiased and variances are large this results in predicted \n",
    "#value being far away from actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52064c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lambda is denoted by alpha parameter in ridge regression the higher the alpha the bigger is the penalty and therefore \n",
    "#the magnitude of coefficients reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad9e195",
   "metadata": {},
   "outputs": [],
   "source": [
    "#So it shrinks parameters and reduce model complexity by reducing coefficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2ae5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ordinary least square regression seeks to find the coefficients that minimize the mean squared error where as ridge \n",
    "#regression tries to find the coefficients that minimize the mean squared error and wants the magnitude of coefficients to\n",
    "#be as small as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a553fdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ordinary least square can suffer from high variance and overfitting when number of predictor variable is too large \n",
    "#hence to address this issue ridge regression is used which uses regularization technique that shrinks the coefficients\n",
    "#towards zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c54598",
   "metadata": {},
   "source": [
    "# Queno 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9670f553",
   "metadata": {},
   "source": [
    "# Assumptions Of Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918fc893",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relationship between independent and dependent variables should be linear which means effect of each independent variable\n",
    "#on the dependent variable is constant and additive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b00842",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The values of dependent variable for one observation should not be influenced by the values of dependent variable for \n",
    "#other observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600b24c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Error terms in regression should be constant across all levels of independence variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb183794",
   "metadata": {},
   "outputs": [],
   "source": [
    "#There should be no perfect collinearity among independent variables which means two or more independent variables \n",
    "#are perfectly linearly related."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef1dca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Errors should be normally distributed with zero mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea4e886",
   "metadata": {},
   "source": [
    "# Queno 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288f6caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The shrinkage of coefficient is achieved by the value of tuning parameter with the use of term called l2 norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cdb56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The value of tuning parameter can be fine tuned using a constant called lambda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136d7317",
   "metadata": {},
   "outputs": [],
   "source": [
    "#When lambda=0 the value of tuning parameter has no effect and ridge regression will produce the classical least square\n",
    "#coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8fe7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#However as lambda increases the value of tuning parameter starts to shrink and the ridge regression coefficients \n",
    "#will get close zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365898e8",
   "metadata": {},
   "source": [
    "# Queno 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a520b1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge regression is used mainly for solving the problem of overfitting where size of data is very large and ridge\n",
    "#regression works by penalizing the coefficient of features and it also minimizes the errors in prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3f865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If we know that any of coefficients have zero effect but which one has it we dont know then we can use ridge regression\n",
    "#to know the effect of every coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3e37b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After that we can plot a bar plot of feastures having coefficient 0 to know the level of importance ofeach feature\n",
    "#and with the help to this level of importance we can select the important feature from dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4364e4",
   "metadata": {},
   "source": [
    "# Queno 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef11760",
   "metadata": {},
   "source": [
    "# Multicollinearity In Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61811e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multicollinearity is a phenomenon in which two or more predictors in multiple regression are highly corelated in r squared\n",
    "#more than 0.7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7924c8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can also check multicollinearity with VIF(Variation inflation Rate) if VIF>10 then multicollinearity is high ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d296c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To reduce multicollinearity we can use regularization technique which keeps all feature but reduce the magnitude of \n",
    "#coefficients of model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf000475",
   "metadata": {},
   "outputs": [],
   "source": [
    "#So ridge regression model is suitable for dataset having high multicollinearity ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802fa3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge regression adds penalty to square the magnitude of coefficients which minimise the sum of square of coefficients\n",
    "#to reduce the impact of corelated predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befa507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It also reduce standard error by adding some bias in estimates of regression and reduction in standard error in regression \n",
    "#estimates significantly increases the reliability of the estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5c26f8",
   "metadata": {},
   "source": [
    "# Queno 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a31dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge regression is using Tikhonov regularised version of covariance matrix of X to generate the estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc39225",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It can have categorical or continous variables in our X matrix as regularisation takes part outside the actual variables\n",
    "#and 'amps' the variance across the diagonal of matrix XtX ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056a28e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this way ridge regression works in categorical or continous variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0cd182",
   "metadata": {},
   "source": [
    "# Queno 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704c7644",
   "metadata": {},
   "source": [
    "# Interpreting Coefficients of Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d11f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge regression performs l2 regularization that it adds factor of sum of squares of coefficients in the optimizatin\n",
    "#objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fab9560",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The ridge regression optimises =Residual sum of square+alpha*(sum of square coefficients).Here alpha is parameter \n",
    "#that balances minimizing RSS VS minimising sum of squares of coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98a6cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALpha can take various values alpha=0  same coefficient as simple linear regression,alpha=infinity where coefficient is \n",
    "#zero because of infinite weight on square of coefficients,0<alpha<infinity where coefficient can be 0 to 1 for simple\n",
    "#linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769e10db",
   "metadata": {},
   "source": [
    "# Queno 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d258a95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Yes ridge regression can be used for timeseries data analysis.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf79b3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge regression is a linear regression technique designed to tacle the issue of multicollinearity in predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decaeee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bayesian method in ridge regression treat model parameters as random variables allowing for modeling of uncertainity which\n",
    "#means that instead of producing point estimates for coefficients bayesian method provides probability disdtribution\n",
    "#over the possible values of these coefficients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0104e163",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This method makes the model learn from large dataset automatically detect pattern and trends and adapt to changing condition\n",
    "#making them invaluable for real world application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcbc850",
   "metadata": {},
   "outputs": [],
   "source": [
    "#So in this way with the help of Bayesian ridge regression time series data analysis can be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c4fed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b641dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
