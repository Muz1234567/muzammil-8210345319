{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d8b96a7",
   "metadata": {},
   "source": [
    "# Queno 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af013896",
   "metadata": {},
   "source": [
    "# Difference Between Logistic Regression model and linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192cfe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear regression is supervised regression model while logistic regression is a supervised classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322d03d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In linear regression we predict value by integer number while in logistic regression we predict value by 1 or 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293c7026",
   "metadata": {},
   "outputs": [],
   "source": [
    "#No activation function is used in linear regression while to convert linear equation to logistic regression equation\n",
    "#activation function is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e2229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#No threshold value is needed in linear regression while threshold value is needed in logistic regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4103e8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In linear regression model we calculate mean square error(mse) to predict the next weight value while we use precision\n",
    "#to predict the next weight value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222a6ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear regression model is used to estimate the dependent variable in case of a change in independent variables while\n",
    "#in logistic regression is used to calculate the probability of an event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e324f031",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LInear regression is based on least square estimation while logistic regression model is based on maximum likelihood \n",
    "#estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e178eb0e",
   "metadata": {},
   "source": [
    "# Queno 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5547ac3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cost function in logistic regression calculates the difference between actual values and values predicted by model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1309744b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For logistic regression the cost function is defined as -log(h thita(x) if y=1\n",
    "#                                                         -log(1-h thita(x) if y=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d513645",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The above two functions can be compressed into a single function that is j(thita)=-i/m[y(i)log(h thita(x(i)))+(1-y(i)log\n",
    "#(1-h thita(x(i)))] \n",
    "#y(i)=actual value of target variable for ith training\n",
    "#x(i)=is the ith training example.\n",
    "#m=no of training example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703485e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The main goal of gradient descent is to minimize the cost value that is min J(thita)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a7e64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now to minimize cost function we need to run the gradient descent function on each parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a20e69",
   "metadata": {},
   "source": [
    "# Queno 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d3f8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overfitting also occurs in logistic regression model which leads to cause model complexity and fits the training data too\n",
    "#closely resulting in poor generalization to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40b692c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#So to avoid overfitting in logistic regression we have to use regularization parameter ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac22000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regularization is a technique used to avoid overfitting in machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaee30a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It does this by adding penalty term to objective function(measures the difference between predicted output of model and\n",
    "#true output.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edec7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A higher value for penalty term leads to stronger regularization and simpler model while low value penalty term leads to \n",
    "#complex model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff55ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are various types of regularization we can use that is lasso regularization ,ridge regularization and elastic net \n",
    "#regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1c4f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso regularization leads to sparse model where many feature coefficients are exactly zero, in ridge regularization \n",
    "#leafdsto model with all coefficient close to zero but not zero while in elastic net leads to model with some coefficients \n",
    "#equal to zero and some close to zero. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c86affe",
   "metadata": {},
   "source": [
    "# Queno 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc16429",
   "metadata": {},
   "source": [
    "# ROC (Receiver Operating Characteristic curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0036c600",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This curve plot two parameters that is ;True Positive Rate And False Positive Rate.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158fd5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#True Positive Rate=True Positive/True positive+false negative\n",
    "#True Positive Rate is the proportion of observations that are correctly predicted to be positive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5ed498",
   "metadata": {},
   "outputs": [],
   "source": [
    "#False Positive Rate=False Positive/True Negative+False Positive\n",
    "#False positive rate is the proportion of observations that are incorrectly predicted to be positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8491c1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In order to visualise which threshold values is best suited for classifier we have to plot ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a505493",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC curve that fall under area at top left corner indicate good performance levels where as ROC curves fall in the other\n",
    "#area at bottom right corner indicate poor performance levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2942a19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Whereas an ROC curve of perfect classifier is combination of two straight lines moving away from baseline towards top left\n",
    "#corner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d355f556",
   "metadata": {},
   "source": [
    "# Queno 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4b50b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are several techniques that can be used to select the best features for logistic regression among them is Recursive\n",
    "#feature elimination,wrapper,filter,forwardselection etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf96b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recursive feasture elimination is a feature selection technique that involves training a model on a subset of features\n",
    "#and then iteratively removing the least important features one by one at last we are left with desired no of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74287e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this way the features that are most important to the model will have greatest impact on performance when least important\n",
    "#are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04871154",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this way the model performance becomes better after removing least important features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b85c06f",
   "metadata": {},
   "source": [
    "# Queno 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14743803",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imbalanced dataset is a type of dataset where distribution of labels across the dataset is not balanced that is distribution\n",
    "#is biased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7cb27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group having more datapoints/sample is known as majority class where the group having less data points is known as minority\n",
    "#class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1316aa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weighted logistic regression can be used to address this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cbdb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weighted logistic regression addresses this issue by assigning different weights to each class based on their prevelance\n",
    "#in dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64d997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The weights are incorporated into loss function during model training by assigning higher weights to minority class and lower\n",
    "#weights to majority class ,the model is encouraged to pay more attention to minority class thereby reducing bias towards \n",
    "#the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e0d320",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After training the weighted logistic regression model is evaluated using appropriate performance metrics such as precision\n",
    "#recall,f1 score and area under ROC curve(AUC) and depending on evaluation result model may be fine tuned further by adjusti\n",
    "#ng class weights or other hyper parameters to achieve better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aeb639",
   "metadata": {},
   "source": [
    "# Queno 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25993e6d",
   "metadata": {},
   "source": [
    "# Challenges In logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71a9071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression faces many challenges such as multicollinearity,overfitting and imbalanced datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3188b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multicollinearity occurs when two or more independent variables have a high corelation with one another in logistic \n",
    "#regression ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099bccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to detect multicollinearity is to calculate the variance inflation factor(vif) for each independent variable\n",
    "#and a VIF value greater than 1.5 indicates multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a120c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To fix multicollinearity one can remove one of highly corelated variables combine them into single variable or can use \n",
    "#dimensionality reduction technique such as principal component analysis to reduce no of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31c74ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a3d185",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
